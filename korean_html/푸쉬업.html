<!DOCTYPE html>
<html lang="eg">
<head>
    <meta charset="UTF-8">
    <!-- Required meta tags -->
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta http-equiv="X-UA-Compatible" content="ie=edge">

    <title>Push Up</title>
    
</head>
<body>
	<div>PUSH UP</div>
	<button id="autoClickBtn" type="button" onclick="init()"
			style="background-color: #4CAF50; border: none; color: white; padding: 15px 32px; text-align: center; text-decoration: none; display: inline-block; font-size: 16px;">
		S T A R T
	</button>
	<div><canvas id="canvas"></canvas></div>
	<div id="label-container"></div>
	<script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@1.3.1/dist/tf.min.js"></script>
	<script src="https://cdn.jsdelivr.net/npm/@teachablemachine/pose@0.8/dist/teachablemachine-pose.min.js"></script>
	<script type="text/javascript">
    // More API functions here:
    // https://github.com/googlecreativelab/teachablemachine-community/tree/master/libraries/pose

    // the link to your model provided by Teachable Machine export panel

    // 1. PUSH-UP_UP
	//2. PUSH-UP_DOWN
	//3. EXIT

	    const URL = "./models/PUSH-UP_MODEL(new)/my-pose-model/";
	    let model, webcam, ctx, labelContainer, maxPredictions;

	    window.onload = function(){
			document.getElementById('autoClickBtn').click();
		}
	    
	    async function init() {
	        const modelURL = URL + "model.json";
	        const metadataURL = URL + "metadata.json";

	        var audio = new Audio('./data/Voice/English/AreYouReady.mp3')
	        audio.play()

	        // load the model and metadata
	        // Refer to tmImage.loadFromFiles() in the API to support files from a file picker
	        // Note: the pose library adds a tmPose object to your window (window.tmPose)
	        model = await tmPose.load(modelURL, metadataURL);
	        maxPredictions = model.getTotalClasses();

	        // Convenience function to setup a webcam
	        const size = 400;
	        const flip = true; 	  // whether to flip the webcam
	        webcam = new tmPose.Webcam(size, size, flip); // width, height, flip
	        await webcam.setup(); // request access to the webcam
	        await webcam.play();
	        window.requestAnimationFrame(loop);

	        // append/get elements to the DOM
	        const canvas = document.getElementById("canvas");
	        canvas.width = size; canvas.height = size;
	        ctx = canvas.getContext("2d");
	        labelContainer = document.getElementById("label-container");
	        for (let i = 0; i < maxPredictions; i++) { // and class labels
	            labelContainer.appendChild(document.createElement("div"));
	        }
	    }

	    async function loop(timestamp) {
	        webcam.update(); // update the webcam frame
	        await predict();
	        window.requestAnimationFrame(loop);
	    }

	    var status = "stand";
	    var count = 0;

	    async function predict() {
	        // Prediction #1: run input through posenet
	        // estimatePose can take in an image, video or canvas html element
	        const { pose, posenetOutput } = await model.estimatePose(webcam.canvas);
	        // Prediction 2: run input through teachable machine classification model
	        const prediction = await model.predict(posenetOutput);
	        

	        if(prediction[0].probability.toFixed(2) >= 0.91) {
	        	if(status=="do"){
	        		count++;
	        		var audio = new Audio('./data/Voice/한글/유학생/' + count%10 +'_유학생.mp3')
	        		audio.play()


	        		if((count >= 10) && (count%10==0)){
		        		var audio = new Audio('./data/Voice/English/VeryGood_UK.mp3')
		        		audio.play()	
		        	}
	        	}

	        	status = "stand";
	        } else if(prediction[1].probability.toFixed(2) >= 0.91) {
	        	status = "do";
	        } 

	        for (let i = 0; i < maxPredictions; i++) {
	            if(i==0){
		            const classPrediction = "DOWN " + ": " + prediction[i].probability.toFixed(2);
		            labelContainer.childNodes[i].innerHTML = classPrediction;	
	            } else if (i==1) {
	            	const classPrediction = "UP "  + ": " + prediction[i].probability.toFixed(2);
	            	labelContainer.childNodes[i].innerHTML = classPrediction;
	            } 
	        }

	        // finally draw the poses
	        drawPose(pose);
	    }

	    function drawPose(pose) {
	        if (webcam.canvas) {
	            ctx.drawImage(webcam.canvas, 0, 0);
	            // draw the keypoints and skeleton
	            if (pose) {
	                const minPartConfidence = 0.5;
	                tmPose.drawKeypoints(pose.keypoints, minPartConfidence, ctx);
	                tmPose.drawSkeleton(pose.keypoints, minPartConfidence, ctx);
	            }
	        }
	    }
</script>


</body>
</html>